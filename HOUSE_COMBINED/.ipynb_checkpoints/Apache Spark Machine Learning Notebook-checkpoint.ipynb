{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population vs. Median Home Prices\n",
    "Linear Regression with Single Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Spark CSV datasource with options specifying:\n",
    "#  - First line of file is a header\n",
    "#  - Automatically infer the schema of the data\n",
    "data = spark.read.csv(\"/Users/cchavez/dev/Group_Project/HOUSE_COMBINED/HOUSE_COMBINED.csv\", header=\"true\", inferSchema=\"true\")\n",
    "data.cache()  # Cache data for faster reuse\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ZIP Code: int, Year: int, Month: int, SalesCount: int, AvgSalesPrice: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()  # drop rows with missing values\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# rename the feature and label columns, replacing spaces with _\n",
    "exprs = [col(column).alias(column.replace(' ', '_')) for column in data.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ZIP Code: int, Year: int, Month: int, SalesCount: int, AvgSalesPrice: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vdata = data.select(*exprs).selectExpr(\"2014_Population_estimate as population\", \"2015_median_sales_price as label\")\n",
    "display(vdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "stages = []\n",
    "assembler = VectorAssembler(inputCols=[\"population\"], outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(vdata)\n",
    "dataset = pipelineModel.transform(vdata)\n",
    "# Keep relevant columns\n",
    "selectedcols = [\"features\", \"label\"]\n",
    "display(dataset.select(selectedcols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = dataset.rdd.map(lambda p: (p.features[0])).collect()\n",
    "y = dataset.rdd.map(lambda p: (p.label)).collect()\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['lines.linewidth'] = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.loglog(x,y)\n",
    "plt.xlim(1.0e5, 1.0e7)\n",
    "plt.ylim(5.0e1, 1.0e3)\n",
    "ax.scatter(x, y, c=\"blue\")\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Goal\n",
    "Predict y = 2015 Median Housing Price\n",
    "Using feature x = 2014 Population Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 2 models, using different regularization parameters\n",
    "modelA = lr.fit(dataset, {lr.regParam:0.0})\n",
    "modelB = lr.fit(dataset, {lr.regParam:100.0})\n",
    "print(\">>>> ModelA intercept: %r, coefficient: %r\" % (modelA.intercept, modelA.coefficients[0]))\n",
    "print(\">>>> ModelB intercept: %r, coefficient: %r\" % (modelB.intercept, modelB.coefficients[0]))\n",
    ">>>> ModelA intercept: 191.29427575139394, coefficient: 3.779789682338248e-05\n",
    ">>>> ModelB intercept: 199.85112564667153, coefficient: 2.1603499483717156e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions\n",
    "Calling ```transform()``` on data adds a new column of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictionsA = modelA.transform(dataset)\n",
    "display(predictionsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsB = modelB.transform(dataset)\n",
    "display(predictionsB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model\n",
    "Predicted vs. True label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "RMSE = evaluator.evaluate(predictionsA)\n",
    "print(\"ModelA: Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsB = modelB.transform(dataset)\n",
    "RMSE = evaluator.evaluate(predictionsB)\n",
    "print(\"ModelB: Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot residuals versus fitted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(modelA,dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import *\n",
    "\n",
    "pop = dataset.rdd.map(lambda p: (p.features[0])).collect()\n",
    "price = dataset.rdd.map(lambda p: (p.label)).collect()\n",
    "predA = predictionsA.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n",
    "predB = predictionsB.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n",
    "\n",
    "pydf = DataFrame({'pop':pop,'price':price,'predA':predA, 'predB':predB})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the pandas DataFrame (pydf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the scatterplot and the two regression models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.loglog(x,y)\n",
    "ax.scatter(x, y)\n",
    "plt.xlim(1.0e5, 1.0e7)\n",
    "plt.ylim(5.0e1, 1.0e3)\n",
    "ax.plot(pop, predA, '.r-')\n",
    "ax.plot(pop, predB, '.g-')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
